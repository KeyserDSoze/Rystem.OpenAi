# Token Summary in Final Response

## Overview

When a conversation completes, the system now provides a comprehensive summary that includes both **cost** and **token breakdown** in the final response message.

## Final Response Format

### Old Format (Cost Only)
```
Completed. Total cost: $0.000342
```

### New Format (Cost + Token Breakdown)
```
Completed. Total cost: $0.000342. Tokens: 250 input + 0 cached (10% cost) + 180 output = 430 total
```

## Example Messages

### Simple Request (No Tool Calls)
```
Completed. Tokens: 150 input + 0 cached (10% cost) + 85 output = 235 total
```

### Multi-Scene Request (With Tools)
```
Completed. Total cost: $0.001205. Tokens: 850 input + 42 cached (10% cost) + 320 output = 1212 total
```

### Complex Workflow (With Planning)
```
Completed. Total cost: $0.003847. Tokens: 2150 input + 180 cached (10% cost) + 680 output = 3010 total
```

## Implementation Details

### Helper Method: `CalculateAggregatedTokens()`

Aggregates token counts across all responses:

```csharp
private static (int InputTokens, int CachedInputTokens, int OutputTokens, int TotalTokens) 
    CalculateAggregatedTokens(List<AiSceneResponse> responses)
{
    // Sums up all token counts from each response
    // Returns tuple with total input, cached, output, and total tokens
}
```

### Three Locations That Display Token Summary

#### 1. **RequestAsync** - Director Decision Point
When director decides NOT to execute again:
```csharp
var (inputTokens, cachedTokens, outputTokens, totalTokens) = CalculateAggregatedTokens(context.Responses);
var tokenSummary = $"Tokens: {inputTokens} input + {cachedTokens} cached (10% cost) + {outputTokens} output = {totalTokens} total";

yield return new AiSceneResponse
{
    Message = context.TotalCost > 0 ? 
        $"Completed. Total cost: ${context.TotalCost:F6}. {tokenSummary}" : 
        $"Completed. {tokenSummary}",
    // ...
};
```

#### 2. **ExecutePlanAsync** - Plan Execution Complete
When plan finishes (fallback director path):
```csharp
var (inputTokens, cachedTokens, outputTokens, totalTokens) = CalculateAggregatedTokens(context.Responses);
var tokenSummary = $"Tokens: {inputTokens} input + {cachedTokens} cached (10% cost) + {outputTokens} output = {totalTokens} total";

yield return YieldAndTrack(context, new AiSceneResponse
{
    Message = context.TotalCost > 0 ? 
        $"Completed. Total cost: ${context.TotalCost:F6}. {tokenSummary}" : 
        $"Completed. {tokenSummary}",
    // ...
});
```

#### 3. **GenerateFinalResponseAsync** - Final Response
Token counts are populated in the final AI-generated response:
```csharp
var finalSceneResponse = new AiSceneResponse { /* ... */ };
if (finalResponse?.Usage != null)
{
    PopulateTokenCounts(finalSceneResponse, finalResponse.Usage);
}
```

## Token Information Breakdown

### InputTokens
- Total number of prompt tokens used
- Includes all messages and system prompts
- Charged at full rate

### CachedInputTokens  
- Tokens reused from prompt cache
- **Charged at 10% of normal input rate** (big savings!)
- Only available in multi-turn conversations using same cache key

### OutputTokens
- Tokens generated by the model
- Charged at full rate
- Always present in responses

### TotalTokens
- Sum of InputTokens + CachedInputTokens + OutputTokens
- Useful for tracking usage

## Practical Examples

### Single Turn Request
```
User: "What is the capital of France?"

Response Flow:
??? Request Processing: 142 input, 0 cached, 48 output = 190 total
??? Status: FinishedNoTool
    Message: "Completed. Tokens: 142 input + 0 cached (10% cost) + 48 output = 190 total"
```

### Multi-Scene Workflow
```
User: "What's the weather in Paris and what year is it?"

Response Flow:
??? Scene 1 (Weather): 250 input, 0 cached, 85 output = 335 total
??? Scene 2 (Time): 200 input, 15 cached, 42 output = 257 total  
??? Status: FinishedOk
    Message: "Completed. Total cost: $0.001562. Tokens: 450 input + 15 cached (10% cost) + 127 output = 592 total"
```

### Multi-Turn Conversation with Cache Reuse
```
Turn 1: 300 input, 0 cached, 150 output = 450 total
Turn 2: 250 input, 75 cached, 120 output = 445 total ? Cache hit!
Turn 3: 280 input, 95 cached, 130 output = 505 total ? More cache reuse!

Total tokens across conversation:
- Input: 830 (full price)
- Cached: 170 (90% discount! Only 10% charged)
- Output: 400
- Total: 1400 tokens
```

## Benefits

? **Cost Transparency**: See exactly what your multi-scene workflow costs
? **Token Visibility**: Understand token usage patterns per request
? **Cache Optimization**: Track cached token reuse for cost savings
? **Debugging**: Identify which requests use most tokens
? **Billing**: Accurate cost estimation for multi-turn conversations

## Accessing Token Data Programmatically

Each response has individual token counts:

```csharp
var responses = await sceneManager.ExecuteAsync(message, /* ... */);

foreach (var response in responses)
{
    if (response.InputTokens.HasValue)
    {
        var input = response.InputTokens.Value;       // Input tokens
        var cached = response.CachedInputTokens.Value; // Cached tokens
        var output = response.OutputTokens.Value;      // Output tokens
        var total = response.TotalTokens.Value;        // Total
    }
}
```

Or get aggregated totals:

```csharp
var responses = await sceneManager.ExecuteAsync(message, /* ... */).ToListAsync();
var (input, cached, output, total) = CalculateAggregatedTokens(responses);

Console.WriteLine($"Total: {input} input + {cached} cached + {output} output = {total} total");
```

## Format Notes

- **Cost Format**: `${cost:F6}` (6 decimal places)
- **Token Format**: Plain integers (no formatting)
- **Cache Note**: Always shows "(10% cost)" reminder
- **Message Flow**: "Completed. " + "Total cost: ${cost}. " + "{tokenSummary}"

---

**Related Documentation:**
- [TOKEN_TRACKING.md](./TOKEN_TRACKING.md) - Token tracking implementation details
- [COST_TRACKING.md](./COST_TRACKING.md) - Cost calculation details
- [SceneManager.cs](../src/Rystem.PlayFramework/Manager/SceneManager.cs) - Implementation
